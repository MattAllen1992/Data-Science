{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('../TextFiles/owlcreek.txt') as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "\n",
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    tokens.append(token)\n",
    "    \n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \t DET \t det \t a\n",
      "man \t NOUN \t nsubj \t man\n",
      "stood \t VERB \t ROOT \t stand\n",
      "upon \t SCONJ \t prep \t upon\n",
      "a \t DET \t det \t a\n",
      "railroad \t NOUN \t compound \t railroad\n",
      "bridge \t NOUN \t pobj \t bridge\n",
      "in \t ADP \t prep \t in\n",
      "northern \t ADJ \t amod \t northern\n",
      "Alabama \t PROPN \t pobj \t Alabama\n",
      ", \t PUNCT \t punct \t ,\n",
      "looking \t VERB \t advcl \t look\n",
      "down \t ADV \t prep \t down\n",
      "\n",
      " \t SPACE \t npadvmod \t \n",
      "\n",
      "into \t ADP \t prep \t into\n",
      "the \t DET \t det \t the\n",
      "swift \t ADJ \t amod \t swift\n",
      "water \t NOUN \t pobj \t water\n",
      "twenty \t NUM \t nummod \t twenty\n",
      "feet \t NOUN \t npadvmod \t foot\n",
      "below \t ADV \t advmod \t below\n",
      ". \t PUNCT \t punct \t .\n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "for token in sentences[1]:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.dep_, '\\t', token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "patterns = [\n",
    "    [{'LOWER':'swimming'}, {'IS_SPACE':True}, {'LOWER':'vigorously'}]\n",
    "]\n",
    "\n",
    "matcher.add('Swimming', patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12881893835109366681, 1274, 1277), (12881893835109366681, 3609, 3612)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "found_matches = matcher(doc)\n",
    "\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12881893835109366681 Swimming 1274 1277 evade the bullets and, swimming\n",
      "vigorously, reach the bank,\n",
      "12881893835109366681 Swimming 3609 3612 shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "# method to print out match strings\n",
    "def show_matches(matches):\n",
    "    for match_id, start, stop in found_matches:\n",
    "        # get string using match_id\n",
    "        string_id = nlp.vocab.strings[match_id]\n",
    "\n",
    "        # extract matched span using start and stop\n",
    "        span = doc[start-5:stop+5]\n",
    "\n",
    "        # show matched values\n",
    "        print(match_id, string_id, start, stop, span.text)\n",
    "        \n",
    "# show matches (shows unique ID for match, start and stop token index of match)\n",
    "show_matches(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12881893835109366681 Swimming 1274 1277 swimming\n",
      "vigorously\n",
      "12881893835109366681 Swimming 3609 3612 swimming\n",
      "vigorously\n"
     ]
    }
   ],
   "source": [
    "# method to print out match sentences\n",
    "def show_matches(matches):\n",
    "    for match_id, start, stop in found_matches:\n",
    "        # get string using match_id\n",
    "        string_id = nlp.vocab.strings[match_id]\n",
    "\n",
    "        # extract matched span using start and stop\n",
    "        span = doc[start:stop]\n",
    "\n",
    "        # show matched values\n",
    "        print(match_id, string_id, start, stop, span.text)\n",
    "        \n",
    "# show matches (shows unique ID for match, start and stop token index of match)\n",
    "show_matches(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
