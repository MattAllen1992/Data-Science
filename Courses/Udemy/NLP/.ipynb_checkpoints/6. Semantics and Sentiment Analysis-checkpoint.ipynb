{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "living-southwest",
   "metadata": {},
   "source": [
    "# Semantics and Sentiment Analysis\n",
    "## 1. Semantics and Text Vectors\n",
    "### Text Vectorization\n",
    "* NLP libraries (e.g. Spacy) have modules which map specific elements of text to numerical vectors\n",
    "* In Spacy, this module is called **Word2Vec** and it is already trained within the medium and large language libraries\n",
    "* Note that as well as creating vectors for individual words, you can also create document vectors, which are the average vector of all the word vectors within them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "charitable-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import spacy\n",
    "\n",
    "# load large library\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "musical-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18963, -0.40309,  0.3535 , -0.47907, -0.43311], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at vector for specific word (first 5 values only)\n",
    "nlp(u'lion').vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "molecular-xerox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 300 dimensions attached to this vector (i.e. word described by 300 values)\n",
    "nlp(u'lion').vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-serve",
   "metadata": {},
   "source": [
    "### Text Similarity\n",
    "* You can compare the similarity of words (or tokens or docs etc.) using Spacy\n",
    "* It will give you a score between 0 and 1 to indicate how similar the vectors are\n",
    "* In the first example below, you can see that cat and pet are strongly similar for example\n",
    "* This is based off the trained algorithm within Spacy's Word2Vec which has mapped the vectors of many words/tokens\n",
    "* The second example below shows that for some words, even if their meaning is opposite (e.g. love and hate), their vector similarity might be high because they're used in similar contexts to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "threatened-fiber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion lion 1.0\n",
      "lion cat 0.52654374\n",
      "lion pet 0.39923766\n",
      "cat lion 0.52654374\n",
      "cat cat 1.0\n",
      "cat pet 0.7505456\n",
      "pet lion 0.39923766\n",
      "pet cat 0.7505456\n",
      "pet pet 1.0\n"
     ]
    }
   ],
   "source": [
    "# create text tokens\n",
    "tokens = nlp(u'lion cat pet')\n",
    "\n",
    "# look at similarity between tokens\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        # use '.similarity' to compare 2 tokens vectors\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strategic-length",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like like 1.0\n",
      "like love 0.65790397\n",
      "like hate 0.6574652\n",
      "love like 0.65790397\n",
      "love love 1.0\n",
      "love hate 0.6393099\n",
      "hate like 0.6574652\n",
      "hate love 0.6393099\n",
      "hate hate 1.0\n"
     ]
    }
   ],
   "source": [
    "# create text tokens\n",
    "tokens = nlp(u'like love hate')\n",
    "\n",
    "# look at similarity between tokens\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        # use '.similarity' to compare 2 tokens vectors\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-darkness",
   "metadata": {},
   "source": [
    "### Vector Attributes\n",
    "* It's sometimes useful to aggregate the 300 dimensions within a single vector\n",
    "* Euclidian L2-Norm = square root of the sum of squared vectors for a specific word/token/doc\n",
    "* There are a number of other attributes attached to our vectors, such as being able to check if they're within our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "circular-breed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684830"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of unique words within our vocabulary (that we have vectors for)\n",
    "# each vector has 300 dimensions, so our vocab is a 684,830 x 300 matrix\n",
    "len(nlp.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spiritual-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "nargle False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "# create text\n",
    "tokens = nlp(u'dog cat nargle')\n",
    "\n",
    "# check if token is within our vocab\n",
    "for token in tokens:\n",
    "    # nargle is a made up word so will have no vector\n",
    "    # has_vector will be False, is_oov (out of vocab) will be true\n",
    "    # the vector_norm is the sum of squares for each value in our vector\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-martial",
   "metadata": {},
   "source": [
    "### Vector Arithmetic\n",
    "* Once words are transformed into vectors, we can perform vector arithmetic on them\n",
    "* This is how similarity is calculated\n",
    "* For example...\n",
    "    * An individual word (e.g. King) is given a numeric vector\n",
    "    * This vector can be plotted/visualized in some dimensional space\n",
    "    * You can then use cosine similarity to determine the distance between this word's vector and another word's vector\n",
    "    * This means you can perform vector arithmetic with the vectorized words\n",
    "    * For example, you could calculate the vector of King - man + woman\n",
    "    * Then you could look for the closest vector in your vector library to this calculated vector\n",
    "    * An example of what it returned could be Queen\n",
    "* This vector arithmetic allows Spacy to interpret similarites between words such as tense, age, gender etc. based on the relationships between their vectors\n",
    "\n",
    "<img src=\"NLP Course Files/Images/WordVectors2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "formal-scanner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'woman', 'she', 'lion', 'who', 'when', 'dare', 'cat', 'love', 'was']\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from scipy import spatial\n",
    "\n",
    "# manually calculate cosine similarity\n",
    "cosine_similarity = lambda vec1, vec2: 1 - spatial.distance.cosine(vec1, vec2)\n",
    "\n",
    "# create text vars\n",
    "king = nlp.vocab['king'].vector\n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector\n",
    "\n",
    "# calculate combo of 3 vectors\n",
    "new_vector = king - man + woman\n",
    "\n",
    "# compare new vector to all words in vocab\n",
    "# create list to store similarities\n",
    "computed_similarities = []\n",
    "\n",
    "# iterate through words in vocab\n",
    "for word in nlp.vocab:\n",
    "    # check if word has a vector, is lowercase and is text\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                # calculate similarity and store as tuple in list\n",
    "                similarity = cosine_similarity(new_vector, word.vector)\n",
    "                computed_similarities.append((word, similarity))\n",
    "\n",
    "# sort list (descending order using lambda expression)\n",
    "computed_similarities = sorted(computed_similarities, key=lambda item:-item[1])\n",
    "\n",
    "# print top 10 similar words\n",
    "print([t[0].text for t in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-convert",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis\n",
    "### Overview\n",
    "* Sentiment can be analysed in many ways, but broadly it looks at polarity (+/-) and strength of sentiment\n",
    "* VADER is a useful library in NLTK that can be used for sentiment analysis\n",
    "* It analyses not only the polarity and strength of individual words, but also those around it\n",
    "    * It will interpret context e.g. \"I did not like\" is negative despite containing \"like\"\n",
    "    * It accounts for capitalisation, punctuation etc. too e.g. \"I LOVE THIS!!!\" received higher strength\n",
    "* It is worth noting that sentiment analysis is a tricky field and no algorithm/model will be perfect\n",
    "* If you consider scenarios such as mixed reviews and sarcasm, it's almost impossible for a model to interpret this perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "infrared-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Matthew.Allen2\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "import nltk\n",
    "\n",
    "# download VADER lexicon\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suspected-charleston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# create instance of analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# create text\n",
    "text = \"This was a good movie.\"\n",
    "\n",
    "# analyze text\n",
    "# shows mix of negative/neutral/positive text and an average\n",
    "# values range between 0 and 1\n",
    "sid.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tender-outside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.425, 'pos': 0.575, 'compound': 0.8877}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create text\n",
    "text = \"This was the best, most awesome movie EVER MADE!!!\"\n",
    "\n",
    "# analyze text\n",
    "sid.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "optimum-buffer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.477, 'neu': 0.523, 'pos': 0.0, 'compound': -0.8074}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create text\n",
    "text = \"This is the worst movie to ever disgrace the screen.\"\n",
    "\n",
    "# analyze text\n",
    "sid.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-rochester",
   "metadata": {},
   "source": [
    "## 3. Amazon Reviews\n",
    "### Text Analysis\n",
    "* We can load in a set of text reviews for movies and analyse the sentiment attached\n",
    "* These reviews already have labels which we could use for classification already\n",
    "* However, we can predict our own sentiment values using VADER and then compare our results to the original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "committed-arbitration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...\n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...\n",
       "2   pos  Amazing!: This soundtrack is my favorite music...\n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...\n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in Amazon reviews data\n",
    "in_path = 'C:/Users/Matthew.Allen2/Documents/GitHub/Data-Science/Courses/Udemy/NLP/NLP Course Files/TextFiles/'\n",
    "df = pd.read_csv(in_path + 'amazonreviews.tsv', sep='\\t')\n",
    "\n",
    "# drop nulls\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# peek at data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unexpected-atlantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5097\n",
       "pos    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chcek mix of positive and negative reviews\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beautiful-letters",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blanks list\n",
    "blanks = []\n",
    "\n",
    "# check for blanks\n",
    "# iterate through dataframe, unpack objects\n",
    "for i, lb, rv in df.itertuples():\n",
    "    # if review is a string\n",
    "    if type(rv) == str:\n",
    "        # if it's empty whitespace\n",
    "        if rv.isspace():\n",
    "            # store index of blanks\n",
    "            blanks.append(i)\n",
    "\n",
    "# drop blanks if necessary\n",
    "#df.drop(blanks, inplace=True)\n",
    "            \n",
    "# check blanks\n",
    "blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "destroyed-richards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first review\n",
    "df.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "agreed-logging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'compound': 0.9454}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# polarity review of first review\n",
    "sid.polarity_scores(df.iloc[0]['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-colleague",
   "metadata": {},
   "source": [
    "### Predicting and Scoring\n",
    "* We can run polarity scores for the entire dataframe, looking at all reviews\n",
    "* From this, we can extract the compound score that best describes all fields (i.e. neg/neu/pos)\n",
    "* Finally, we can define positive and negative review labels based on their compound scores (i.e. neg < 0 <= pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "indirect-benefit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound comp_score  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454        pos  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957        pos  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858        pos  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814        pos  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781        pos  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate polarity scores for whole dataframe\n",
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "# extract compound score specifically (most relevant score)\n",
    "df['compound'] = df['scores'].apply(lambda scores: scores['compound'])\n",
    "\n",
    "# create labels based on >= 0 for +ve reviews\n",
    "df['comp_score'] = df['compound'].apply(lambda score: 'pos' if score >= 0 else 'neg')\n",
    "\n",
    "# check output\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-ridge",
   "metadata": {},
   "source": [
    "Confusion Matrix:\n",
    "* This shows us that it's not doing an horrific job of classifying\n",
    "* Most positive reviews are being correctly classified\n",
    "* It's having issues with negative reviews though, likely due to sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "integrated-prairie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>2622</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>434</td>\n",
       "      <td>4469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   neg   pos\n",
       "Actual               \n",
       "neg        2622  2475\n",
       "pos         434  4469"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "# load libraries\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = pd.crosstab(df['label'], df['comp_score'], rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-miller",
   "metadata": {},
   "source": [
    "Accuracy and Other Scores:\n",
    "* Overall accuracy is ~71%\n",
    "* A model which randomly guessed would get around 50% so it's definitely an improvement on a random model\n",
    "* Our positive cases are mostly being correctly guessed, with good recall and f1\n",
    "* Whilst negative cases are trickier and receive a lower recall and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "demographic-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.91%\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print(str(round(accuracy_score(df['label'], df['comp_score']) * 100,2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "homeless-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.51      0.64      5097\n",
      "         pos       0.64      0.91      0.75      4903\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.70     10000\n",
      "weighted avg       0.75      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(df['label'], df['comp_score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
