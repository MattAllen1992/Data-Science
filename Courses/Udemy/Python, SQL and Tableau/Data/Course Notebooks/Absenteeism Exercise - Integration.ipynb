{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating our Model\n",
    "Here we will use Python as a middle man between SQL and Tableau, using the pymysql library to create a connection to SQL, exectuting queries to manipulate data in a SQL database.\n",
    "\n",
    "Note that there are many alternatives to this method, such as using TabPy to directly communicate between Python and Tableau, cutting out the SQL component. Each method has its pros and cons, but using SQL to store the data in a database is a robust way (and common business practice) to store and access data.\n",
    "\n",
    "### Loading our Modules\n",
    "Steps:\n",
    "* Load the class module containing methods to load data, pre-process (using our scaler) and model (using our logistic regression model).\n",
    "* Instantiate the model class from the module and use it to pre-process the data (including standardizing the inputs using the pre-created scaler object) and using the model to predict outputs based on the new inputs (using our pre-created model object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>179</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>361</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.873365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>179</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.198570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  \\\n",
       "0         0       0.0         0         1            6   \n",
       "1         1       0.0         0         0            6   \n",
       "2         0       0.0         0         1            6   \n",
       "3         0       0.0         0         1            6   \n",
       "4         1       0.0         0         0            6   \n",
       "\n",
       "   Transportation Expense  Age  Body Mass Index  Education  Children  Pet  \\\n",
       "0                     179   30               19          1         0    0   \n",
       "1                     361   28               27          0         1    4   \n",
       "2                     155   34               25          0         2    0   \n",
       "3                     179   40               22          1         2    0   \n",
       "4                     155   34               25          0         2    0   \n",
       "\n",
       "   Probability  Prediction  \n",
       "0     0.122469           0  \n",
       "1     0.873365           1  \n",
       "2     0.266253           0  \n",
       "3     0.198570           0  \n",
       "4     0.720861           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load class module\n",
    "from absenteeism_module import *\n",
    "\n",
    "# instantiate model using new data\n",
    "model = absenteeism_model('model', 'scaler')\n",
    "\n",
    "# load and pre-process data\n",
    "model.load_and_clean_data('Absenteeism_new_data.csv')\n",
    "\n",
    "# store predicted outputs in df\n",
    "df_new_obs = model.predicted_outputs()\n",
    "\n",
    "# show predicted outputs of model\n",
    "model.predicted_outputs().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to SQL\n",
    "Steps:\n",
    "* Using pymysql to allow the writing and running of SQL/Python queries.\n",
    "* Create a connection to a MySQL database (that I've created in this case).\n",
    "* Create a cursor to directly interact with the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library to connect Python and SQL (specifically Jupyter and MySQL)\n",
    "import pymysql\n",
    "\n",
    "# create connection to SQL DB\n",
    "# this is the equivalent of opening a query in SQL and typing/running queries in there\n",
    "conn = pymysql.connect(host = 'localhost', database = 'predicted_outputs', user = 'root', password = 'Gafro010')\n",
    "\n",
    "# create cursor to directly interact with your DB\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to SQL (loops, slow)\n",
    "Source: https://www.dataquest.io/blog/sql-insert-tutorial/\n",
    "\n",
    "A few key points on the below:\n",
    "* Loops can be quite slow, therefore this code is instructional only and a batch method should be used (see code below this).\n",
    "* There is an important distinction between single quotes \\' and backticks \\` when writing SQL queries in Python:\n",
    "    * Single quotes are simply used to specify strings (e.g. the sql query itself can be written inside either single or double quotes).\n",
    "    * Backticks are specifically used to reference tables and columns (i.e. variable names). If you use quotes here, you will receive \"1054 internal error\" or \"error 1064\" telling you that your syntax is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'\\x00', b'\\x00', b'\\x00', b'\\x01', 6, 179, 30, 19, b'\\x01', 0, 0, 0.122469, b'\\x00')\n"
     ]
    }
   ],
   "source": [
    "# rename cols to match SQL table names\n",
    "df_new_obs.columns = ['reason_1', 'reason_2', 'reason_3', 'reason_4', 'month_value', 'transportation_expense', 'age', 'body_mass_index',\n",
    "                      'education', 'children', 'pet', 'probability', 'prediction']\n",
    "\n",
    "# store column names as list of strings\n",
    "cols = \"`,`\".join([str(i) for i in df_new_obs.columns.tolist()])\n",
    "\n",
    "# iterate through df\n",
    "for i, row in df_new_obs.iterrows():\n",
    "    # create SQL query to insert data into table columns\n",
    "    # creates %s for the number of items in the row (i.e. length of row - 1 with the final %s afterwards)\n",
    "    sql = \"INSERT INTO `predicted_outputs` (`\" + cols + \"`) VALUES (\" + \"%s,\" * (len(row) - 1) + \"%s)\"\n",
    "    \n",
    "    # execute query, using data in each row (tuple stores rows in comma separated list instead of native pandas series object)\n",
    "    cursor.execute(sql, tuple(row)) # executes above SQL, substituting the row in place of %s\n",
    "    \n",
    "    # commit changes to DB\n",
    "    conn.commit()\n",
    "    \n",
    "# check above commits using select query\n",
    "# select data from table\n",
    "sql = 'SELECT * FROM predicted_outputs;'\n",
    "cursor.execute(sql)\n",
    "\n",
    "# iterate throgh fetched data (show first row only for check)\n",
    "# NOTE: bits are returned with the prefix b'\\x00' for 0 and b'\\x01' for 1\n",
    "result = cursor.fetchall()\n",
    "for i in result:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note below that the number of rows of our dataframe and the length of our data now present in our SQL DB are identical (40 rows in each).\n",
    "\n",
    "This is a good check that the data we intended to be written to our DB has been, and that it hasn't been duplicated etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Database\n",
    "Steps:\n",
    "* Re-create database for fresh start\n",
    "* Re-create table for fresh start (including definition of columns and datatypes)\n",
    "* This is to ensure the above steps (i.e. loading data to DB) is cleared so that the below code can run from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1051, \"Unknown table 'predicted_outputs.predicted_outputs'\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop and re-create DB\n",
    "cursor.execute('DROP DATABASE IF EXISTS predicted_outputs;')\n",
    "cursor.execute('CREATE DATABASE IF NOT EXISTS predicted_outputs;')\n",
    "\n",
    "# select DB\n",
    "cursor.execute('USE predicted_outputs;')\n",
    "\n",
    "# drop and re-create table (specifying data types and var names)\n",
    "cursor.execute('DROP TABLE IF EXISTS predicted_outputs;')\n",
    "cursor.execute('CREATE TABLE predicted_outputs(Reason_1 BIT NOT NULL, Reason_2 BIT NOT NULL, Reason_3 BIT NOT NULL, Reason_4 BIT NOT NULL, month_value INT NOT NULL, transportation_expense INT NOT NULL, age INT NOT NULL, body_mass_index INT NOT NULL, education BIT NOT NULL, children INT NOT NULL, pet INT NOT NULL, probability FLOAT NOT NULL, prediction BIT NOT NULL);')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe to SQL (directly/fast, no loops)\n",
    "Source: https://www.dataquest.io/blog/sql-insert-tutorial/\n",
    "\n",
    "This method is far easier to write than the above loop and also allows you to batch the process to avoid OOM. It's also quicker to run as you're not iteratively looping through every row of a potentially huge dataframe.\n",
    "\n",
    "**NOTE:** It's important to specify 'index=False' in the 'to_sql' method if your dataframe doesn't have an index column (i.e. when you view your df.head(), there shouldn't be an index column on the left). If you don't specify this, then it will complain saying that it can't find an index column and won't run your code.\n",
    "\n",
    "The 'if_exists' component is useful too, as it will append your query to existing data if present, or create a table from scratch if not, saving you the hassle of that extra step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library to store connection settings\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# create sqlalchemy engine (i.e. connections settings string)\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user='root',\n",
    "                               pw='Gafro010',\n",
    "                               db='predicted_outputs'))\n",
    "\n",
    "# write dataframe to SQL DB\n",
    "# write to specified table, using engine connection settings above,\n",
    "# append to existing or create new if not existing, chunk df to avoid OOM\n",
    "df_new_obs.to_sql('predicted_outputs', con = engine, if_exists = 'append', chunksize = 1000, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check that our data has been committed to the database, the first row by itself (i.e. the execute statement) will return the number of rows of the selection if written by itself. The second part returns the first row of the data which we can see matches our datafarme perfectly.\n",
    "\n",
    "**NOTE:** it's important to close your connection after completing your code, it is simply best practice to avoid excessive connections and potential for things to go wrong/get confused during query writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason_1</th>\n",
       "      <th>reason_2</th>\n",
       "      <th>reason_3</th>\n",
       "      <th>reason_4</th>\n",
       "      <th>month_value</th>\n",
       "      <th>transportation_expense</th>\n",
       "      <th>age</th>\n",
       "      <th>body_mass_index</th>\n",
       "      <th>education</th>\n",
       "      <th>children</th>\n",
       "      <th>pet</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>179</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reason_1  reason_2  reason_3  reason_4  month_value  \\\n",
       "0         0       0.0         0         1            6   \n",
       "\n",
       "   transportation_expense  age  body_mass_index  education  children  pet  \\\n",
       "0                     179   30               19          1         0    0   \n",
       "\n",
       "   probability  prediction  \n",
       "0     0.122469           0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_obs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'\\x00', b'\\x00', b'\\x00', b'\\x01', 6, 179, 30, 19, b'\\x01', 0, 0, 0.122469, b'\\x00')\n"
     ]
    }
   ],
   "source": [
    "# select and show data from table\n",
    "cursor.execute('SELECT * FROM predicted_outputs;')\n",
    "results = cursor.fetchall()\n",
    "for i in results:\n",
    "    print(i)\n",
    "    break\n",
    "    \n",
    "# close connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Data for Tableau\n",
    "Once the above steps have been completed, we have our final dataset in SQL. Here, we can use the MySQL Workbench interface to export the data as a CSV which we will then use as our data source for Tableau."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
