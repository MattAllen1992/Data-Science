{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Absenteeism at Work (ML)\n",
    "### Load Data\n",
    "Pull in pre-processed data and load relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Absenteeism Time in Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  Day of the Week  \\\n",
       "0         0         0         0         1            7                1   \n",
       "1         0         0         0         0            7                1   \n",
       "2         0         0         0         1            7                2   \n",
       "3         1         0         0         0            7                3   \n",
       "4         0         0         0         1            7                3   \n",
       "\n",
       "   Transportation Expense  Distance to Work  Age  Daily Work Load Average  \\\n",
       "0                     289                36   33                  239.554   \n",
       "1                     118                13   50                  239.554   \n",
       "2                     179                51   38                  239.554   \n",
       "3                     279                 5   39                  239.554   \n",
       "4                     289                36   33                  239.554   \n",
       "\n",
       "   Body Mass Index  Education  Children  Pets  Absenteeism Time in Hours  \n",
       "0               30          0         2     1                          4  \n",
       "1               31          0         1     0                          0  \n",
       "2               31          0         0     0                          2  \n",
       "3               24          0         2     0                          4  \n",
       "4               30          0         2     1                          2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# read in data\n",
    "df = pd.read_csv('S:/Matt/Data Science/Udemy/Python, SQL and Tableau/Data/absent_out_data (my_file).csv')\n",
    "\n",
    "# peek at data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Overview:\n",
    "* A logistic regression produces a binary output of 0 or 1, allowing us to perform a 2 class classification.\n",
    "* Here, we will classify each individual/row of our data as either 'excessively absent' (1) or not (0).\n",
    "* To do this, we will use the median of the target variable (absenteeism in hours) as our class decision boundary.\n",
    "* Using the median ensures that we are splitting our data ~50:50. For logistic regression, it is important that both output classes are relatively evenly distributed (down to a 60:40 split at the most drastic) to avoid over/under-sampling and simply outputting one class predominantly in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45571429]\n"
     ]
    }
   ],
   "source": [
    "# create target variable\n",
    "targets = np.where(df['Absenteeism Time in Hours'] >\n",
    "                   df['Absenteeism Time in Hours'].median(), 1, 0)\n",
    "\n",
    "# add targets to df\n",
    "df['Excessive Absenteeism'] = targets\n",
    "\n",
    "# check distribution of targets\n",
    "print(targets.sum() / targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now remove our previous target variable, leaving us with the binary target only. We will also checkpoint our df to ensure we have a safe copy moving forwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove redundant col and store in new df\n",
    "df_pp = df.drop(['Absenteeism Time in Hours', 'Day of the Week', 'Daily Work Load Average', 'Distance to Work'], axis=1)\n",
    "\n",
    "# check new df is distinct from original (i.e. successful checkpoint)\n",
    "df_pp is df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Excessive Absenteeism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>289</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>279</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>289</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  \\\n",
       "0         0         0         0         1            7   \n",
       "1         0         0         0         0            7   \n",
       "2         0         0         0         1            7   \n",
       "3         1         0         0         0            7   \n",
       "4         0         0         0         1            7   \n",
       "\n",
       "   Transportation Expense  Age  Body Mass Index  Education  Children  Pets  \\\n",
       "0                     289   33               30          0         2     1   \n",
       "1                     118   50               31          0         1     0   \n",
       "2                     179   38               31          0         0     0   \n",
       "3                     279   39               24          0         2     0   \n",
       "4                     289   33               30          0         2     1   \n",
       "\n",
       "   Excessive Absenteeism  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at data\n",
    "df_pp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Inputs\n",
    "Overview:\n",
    "* We have multiple input variables/features, each with different scales (min, max, avg etc.), this means that when we run them through our model, our model may infer that higher values carry more significance, negative values mean something drastic etc.\n",
    "* Therefore, we must standardize our inputs (subtract mean, divide by std.) to ensure they all have the same (or very similar) scales, centred around 0, ranging between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features and targets\n",
    "#X = df_pp.iloc[:, :-1]\n",
    "#y = df_pp['Excessive Absenteeism']\n",
    "\n",
    "# load libraries\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# instantiate scaler (subtract mean, divide by std.)\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# fit scaler to data\n",
    "#scaler.fit(X)\n",
    "\n",
    "# apply scaler (centre each feature around 0 with ~1 std.)\n",
    "#X_scaled = scaler.transform(X)\n",
    "\n",
    "# peek at data\n",
    "#X_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above (commented out) code will scale all our features, which is an issue because some of our features are dummy variables and already scaled (i.e. can only be 0 or 1 due to binary dummies).\n",
    "\n",
    "This isn't necessarily an issue, as we could still produce a good model from scaling these dummies, but we would lose the ability of saying \"for every unit change in our dummy variable, we see x change in our predicted value\" when we come to assess our co-efficients and odds ratios later on.\n",
    "\n",
    "Therefore, the below code implements a custom scaler class where we can choose to scale only selected features (thus excluding our dummy variables) and retain the ability to quantify unit changes in our dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass copy=True, with_mean=True, with_std=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>-1.574681</td>\n",
       "      <td>2.130803</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>-0.654143</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>0.854936</td>\n",
       "      <td>0.405184</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  \\\n",
       "0         0         0         0         1     0.030796   \n",
       "1         0         0         0         0     0.030796   \n",
       "2         0         0         0         1     0.030796   \n",
       "3         1         0         0         0     0.030796   \n",
       "4         0         0         0         1     0.030796   \n",
       "\n",
       "   Transportation Expense       Age  Body Mass Index  Education  Children  \\\n",
       "0                1.005844 -0.536062         0.767431          0  0.880469   \n",
       "1               -1.574681  2.130803         1.002633          0 -0.019280   \n",
       "2               -0.654143  0.248310         1.002633          0 -0.919030   \n",
       "3                0.854936  0.405184        -0.643782          0  0.880469   \n",
       "4                1.005844 -0.536062         0.767431          0  0.880469   \n",
       "\n",
       "       Pets  \n",
       "0  0.268487  \n",
       "1 -0.589690  \n",
       "2 -0.589690  \n",
       "3 -0.589690  \n",
       "4  0.268487  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features and targets\n",
    "X = df_pp.iloc[:, :-1]\n",
    "y = df_pp['Excessive Absenteeism']\n",
    "\n",
    "# load libraries\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create custom scaler class\n",
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns, copy=True, with_mean=True, with_std=True):\n",
    "        self.scaler = StandardScaler(copy, with_mean, with_std)\n",
    "        self.columns = columns\n",
    "        self.mean_ = None\n",
    "        self.var_ = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns], y)\n",
    "        self.mean_ = np.mean(X[self.columns])\n",
    "        self.var_ = np.var(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        init_col_order = X.columns\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n",
    "        X_not_scaled = X.loc[:, ~X.columns.isin(self.columns)]\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]\n",
    "    \n",
    "# extract cols to scale (i.e. all except dummy features)\n",
    "cols_to_omit = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Education']\n",
    "\n",
    "cols_to_scale = [x for x in X.columns.values if x not in cols_to_omit]\n",
    "\n",
    "# fit custom scaler to data\n",
    "scaler = CustomScaler(cols_to_scale)\n",
    "\n",
    "# fit scaler to data\n",
    "scaler.fit(X)\n",
    "\n",
    "# transform data\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# view data after standardization\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Train and Test Sets\n",
    "Here we will split our dataset into train (80%) and test (20%) sets so that we can validate our results and also ensure that we're not leaking our validation data to the model. We will also seed the randomness of the split to ensure that our results are directly comparable each time instead of producing entirely new results with different train/test splits each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 11) (140, 11) (560,) (140,)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split dataset (seed randomness for consistent results)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, train_size = 0.8, random_state = 20) # 80:20 train:test split\n",
    "\n",
    "# check shape of vars\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Model\n",
    "Overview:\n",
    "* We will build our logistic regression model, fit it to our training set and then test the score of the model.\n",
    "* We score it by comparing the predicted results to the known outputs and assessing how similar they are (~77% here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7767857142857143\n",
      "0.7767857142857143\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# instantiate model\n",
    "reg = LogisticRegression()\n",
    "\n",
    "# fit model to data\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# check in-built score of model\n",
    "print(reg.score(X_train, y_train))\n",
    "\n",
    "# check manual score of model (proof that the above method is a shorthand for the below code)\n",
    "y_pred = reg.predict(X_train)\n",
    "print(np.sum(y_pred == y_train) / y_train.shape[0]) # % correct matches of total values (i.e. train accuracy %)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Logistic Regression Function\n",
    "Overview:\n",
    "* The above code is a fairly high level view of our model.\n",
    "* In order to fully understand our model, tweak it and feel confident with our analysis, we should dig into the details of the model function.\n",
    "* Any regression (linear or logistic) is designed to optimize a function in order to achieve the best fit to our training data. In order to do this, it assigned weights to each of the input variables/features which it then adjusts during optimization.\n",
    "* Here, we will expose these weights (a.k.a. co-efficients) as well as the intercept (a.k.a. bias, the only other part of our model function) and summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.60957471])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view intercept\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.77151176,  0.93168817,  3.09210221,  0.8090592 ,  0.00781237,\n",
       "         0.62505482, -0.17390339,  0.28829409, -0.24081615,  0.35753531,\n",
       "        -0.27337422]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view co-efficients\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Month Value',\n",
       "       'Transportation Expense', 'Age', 'Body Mass Index', 'Education',\n",
       "       'Children', 'Pets'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# co-efficient labels (i.e. features)\n",
    "X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Names</th>\n",
       "      <th>Co-Efficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.609575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.771512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.931688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reason_3</td>\n",
       "      <td>3.092102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.809059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.625055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.173903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.288294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>-0.240816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.357535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.273374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature Names  Co-Efficients\n",
       "0                Intercept      -1.609575\n",
       "1                 Reason_1       2.771512\n",
       "2                 Reason_2       0.931688\n",
       "3                 Reason_3       3.092102\n",
       "4                 Reason_4       0.809059\n",
       "5              Month Value       0.007812\n",
       "6   Transportation Expense       0.625055\n",
       "7                      Age      -0.173903\n",
       "8          Body Mass Index       0.288294\n",
       "9                Education      -0.240816\n",
       "10                Children       0.357535\n",
       "11                    Pets      -0.273374"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a summary table of the above\n",
    "summary_table = pd.DataFrame(columns = ['Feature Names'], data = X.columns.values)\n",
    "summary_table['Co-Efficients'] = reg.coef_.transpose()\n",
    "summary_table.index = summary_table.index + 1 # free up 0th index\n",
    "summary_table.loc[0] = ['Intercept', reg.intercept_[0]] # fill with intercept (to appear at top)\n",
    "summary_table = summary_table.sort_index()\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the Co-Efficients\n",
    "Notes:\n",
    "* Co-efficients are the weights given to each feature, therefore if the co-efficients are 0 (or close to it) then our model is saying that these features have little or no significance in the prediction of our targets.\n",
    "* Similarly, the odds ratio tells you what to multiply your log odds by in order to produce the final function. Therefore, any value which is 1 (or close to it) is not changing at all, and similarly has little or no prediction power.\n",
    "* Therefore, we can select and remove any features which have a co-efficient of 0 and/or an odds ratio of 1 (they should always occur together as they are mathematically linked).\n",
    "* **NOTE:** because we created our custom scaler class earlier on, we can now effectively discuss unit changes in our dummy variables (e.g. for 1 unit change in 'Reason_3', we see people are 22 times more likely to be absent than someone else). Previously, we wouldn't have been able to do this as our dummy variables had been scaled to non-easily interpretable numbers (i.e. not simply binary values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Names</th>\n",
       "      <th>Co-Efficients</th>\n",
       "      <th>Odds Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reason_3</td>\n",
       "      <td>3.092102</td>\n",
       "      <td>22.023327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.771512</td>\n",
       "      <td>15.982778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.931688</td>\n",
       "      <td>2.538791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.809059</td>\n",
       "      <td>2.245794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.625055</td>\n",
       "      <td>1.868348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.357535</td>\n",
       "      <td>1.429801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.288294</td>\n",
       "      <td>1.334150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.007843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.173903</td>\n",
       "      <td>0.840378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>-0.240816</td>\n",
       "      <td>0.785986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pets</td>\n",
       "      <td>-0.273374</td>\n",
       "      <td>0.760808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.609575</td>\n",
       "      <td>0.199973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature Names  Co-Efficients  Odds Ratio\n",
       "3                 Reason_3       3.092102   22.023327\n",
       "1                 Reason_1       2.771512   15.982778\n",
       "2                 Reason_2       0.931688    2.538791\n",
       "4                 Reason_4       0.809059    2.245794\n",
       "6   Transportation Expense       0.625055    1.868348\n",
       "10                Children       0.357535    1.429801\n",
       "8          Body Mass Index       0.288294    1.334150\n",
       "5              Month Value       0.007812    1.007843\n",
       "7                      Age      -0.173903    0.840378\n",
       "9                Education      -0.240816    0.785986\n",
       "11                    Pets      -0.273374    0.760808\n",
       "0                Intercept      -1.609575    0.199973"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate log odds (i.e. get exponentials of standardized co-efficients)\n",
    "summary_table['Odds Ratio'] = np.exp(summary_table['Co-Efficients'])\n",
    "summary_table.sort_values('Odds Ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above table, our dummy features are the 4 reasons as well as education. Because we did not standardize our dummy values (they are simply 0 or 1), we can easily interpret the results. For example, reason 3 was poisoning, and these values show us that someone who has been poisoned is likely to have 3 more absent hours than a non-poisoned employee. It also shows us that someone who's been poisoned is 22 times more likely to be excessively absent than someone who hasn't. So that's how you interpret both the co-efficient and odds ratio values.\n",
    "\n",
    "From this, we can begin picking up reasons behind our key predictors. For example, the 4 reasons for sickness (i.e. poisoning, pregnancy, general illness etc.) are the biggest contributors towards excessive absence as you might expect. Also, people with kids or who spend more money on transport are also more likely to be absent for longer. You can also see that people with a higher BMI, who are more likely to be unfit/in poor shape, are also more likely to be ill longer.\n",
    "\n",
    "In contrast, the older you are, the better your education and the more pets you have all contribute towards a lower likelihood of excessive illness. This is perhaps because adults take better care of themselves and have less sick days, a better education could lead to greater importance of job and perhaps responsibility not to take sick days and finally that if you have many pets, it's likely you live with other people and therefore don't take sole responsibility for taking days off for the vets etc.\n",
    "\n",
    "**NOTE:** standardization of features results in better model accuracy because scaled, consistent inputs do not throw off the model by introducing bias etc. However, you also lose the interpretability of your data, because in the summary table above you aren't looking at a change in e.g. age in years, you're looking at scaled age (where 0.2 could reprent 65 years for example). Therefore, you can produce both tables (i.e. one scaled, one not) if you want to fully explain your results for readers.\n",
    "\n",
    "### Simplifying the Model (Backward Elmination)\n",
    "Machine learning models require a trade off between simplicity (fewer features) and accuracy (enough valuable data/features to create a good predictor). From the above table we can see that certain features appear to have little or no impact on our predictive power, therefore we will remove them, ensure that the accuracy of our model is not significantly affected and proceed.\n",
    "\n",
    "**NOTE:** I have removed day of the week, daily work load average and distance to work retrospectively (i.e. in an earlier chunk of code) so you will not see the changes in order below for example, they have already happened.\n",
    "\n",
    "### Testing the Model\n",
    "We will now use our test data to validate the accuracy of our model. Our model scores at around 74% which is encouraging as it's close to our train accuracy. We are fairly happy then that it is not over or under fitted excessively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357142857142858"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assess model with test data\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression works by calculating a probability that a sample should be in each class. For example, you might have a 75% probability of being class 0 (not excessively absent) and 25% of being class 1. The model then sets a threshold (normally 50%) and says if you're below that then you're assigned class 0, above and you're assigned class 1.\n",
    "\n",
    "To extract these probabilities so we have full granularity of data, we can use the following method. The first column is the probability of class 0, whilst the second is probability of class 1 (i.e. excessive absence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24533653, 0.39082409, 0.51670907, 0.24231768, 0.91642259])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view predicted probabilities\n",
    "X_test_pred_prob = reg.predict_proba(X_test)\n",
    "\n",
    "# extract probability of class 1/excessive absence only\n",
    "X_test_pred_prob[:, 1][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save our Module\n",
    "Overview:\n",
    "* Save our model (i.e. 'reg' variable) into a file which can be read/loaded as it's own file.\n",
    "* We will use pickle to package and store it for transport (you then use pickle to unpack it when you want to use it again).\n",
    "* **NOTE:** Pickle is a way of serializing (i.e. converting code to strings) and deserialiazing (strings to code/python objects). You should be careful when using it on external files as viruses can be activated this way. Also, it can be quite slow for large files and should always be used on code from the same version of Python as it was written in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pickle\n",
    "\n",
    "# store model in file called 'model'\n",
    "with open('model', 'wb') as file:\n",
    "    pickle.dump(reg, file) # dump serializes code to a string (load is the inverse)\n",
    "\n",
    "# store scaler in file called 'scaler'\n",
    "with open('scaler', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
