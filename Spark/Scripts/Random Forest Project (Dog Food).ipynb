{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "grateful-organic",
   "metadata": {},
   "source": [
    "# Random Forest Project\n",
    "## 1) Brief\n",
    "* This data shows how 4 compounds (A, B, C and D) make up a dog food recipe are linked to whether or not the dog food spoils too early\n",
    "* We will run a random forest to determine which of the 4 compounds is causing the early spoilage and try to infer thresholds (i.e. % amounts) of each compound which are important to the outcome\n",
    "\n",
    "## 2) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disciplinary-planning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load libs\n",
    "import findspark\n",
    "\n",
    "# store location of spark files\n",
    "findspark.init('/home/matt/spark-3.0.2-bin-hadoop3.2')\n",
    "\n",
    "# load libs\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# start new session\n",
    "spark = SparkSession.builder.appName('tree').getOrCreate()\n",
    "\n",
    "# read in data\n",
    "df = spark.read.csv('Data/dog_food.csv', inferSchema=True, header=True)\n",
    "\n",
    "# show schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "standard-witch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+\n",
      "|  A|  B|   C|  D|Spoiled|\n",
      "+---+---+----+---+-------+\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "|  5|  6|12.0|  7|    1.0|\n",
      "|  6|  2|13.0|  6|    1.0|\n",
      "+---+---+----+---+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# peek at data\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-thing",
   "metadata": {},
   "source": [
    "## 3) Results\n",
    "* Here we build a simple decision tree model which assesses the relationship between features (mix of compounds in the dog food) and the outcome (whether or not the dog food spoils early)\n",
    "* This is actually a very simple problem that allows us to just look at the feature importances i.e. which feature is most important in regards to separating the data (based on outcome/spoilage) with the highest purity\n",
    "* Clearly we can see that feature 2 (i.e. index position 2 = compound C) is by far the highest predictor of spoilage and hence this compound should be removed to prevent early spoilage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "egyptian-scanner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {1: 0.0019, 2: 0.9832, 3: 0.0149})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libs for converting to spark-friendly format (i.e. features vector)\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# create assembler to convert 4 feature cols into 1\n",
    "assembler = VectorAssembler(inputCols=['A', 'B', 'C', 'D'],outputCol=\"features\")\n",
    "\n",
    "# create single features column\n",
    "output = assembler.transform(df)\n",
    "\n",
    "# load random forest libs\n",
    "from pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier\n",
    "\n",
    "# create random forest classifier\n",
    "rfc = DecisionTreeClassifier(labelCol='Spoiled', featuresCol='features')\n",
    "\n",
    "# select final data (features and outcomes only)\n",
    "final_data = output.select('features','Spoiled')\n",
    "\n",
    "# fit model to final data\n",
    "rfc_model = rfc.fit(final_data)\n",
    "\n",
    "# show feature importances\n",
    "rfc_model.featureImportances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
