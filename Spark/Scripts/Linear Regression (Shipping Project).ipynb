{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standing-fraction",
   "metadata": {},
   "source": [
    "# Linear Regression: Predicting Crew Size\n",
    "## 1.) Brief\n",
    "* We must accurately estimate of number of crew per ship\n",
    "* Based on knowledge of existing ships, predict crew number for new ships\n",
    "* Different cruise lines have significantly different distributions of crew members per ship\n",
    "    * This variable is therefore important and should be used in our analysis/model\n",
    "    * It is a string in the raw data, so we must use **StringIndexer()** to process it (more below)\n",
    "    \n",
    "## 2.) Data Load and Pre-Processing\n",
    "* We'll load our data in from a CSV\n",
    "* Then we'll investigate for any cleaning steps required (missing data etc.)\n",
    "* Finally, we'll transform the data into a Spark-friendly input (i.e. 1 label, 1 feature column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forward-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### setup pyspark ###\n",
    "# load libs\n",
    "import findspark\n",
    "\n",
    "# store location of spark files\n",
    "findspark.init('/home/matt/spark-3.0.2-bin-hadoop3.2')\n",
    "\n",
    "# load libs\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# start new session\n",
    "spark = SparkSession.builder.appName('crew').getOrCreate()\n",
    "\n",
    "### load data ###\n",
    "# read in data\n",
    "df = spark.read.csv('Data/cruise_ship_info.csv', inferSchema=True, header=True)\n",
    "\n",
    "# show schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ideal-connectivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# peek at data\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "western-rally",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+---+-------+----------+------+------+-----------------+----+\n",
      "|Ship_name|Cruise_line|Age|Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+---------+-----------+---+-------+----------+------+------+-----------------+----+\n",
      "|        0|          0|  0|      0|         0|     0|     0|                0|   0|\n",
      "+---------+-----------+---+-------+----------+------+------+-----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load null check libs\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "# check nulls by column\n",
    "df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-feature",
   "metadata": {},
   "source": [
    "## 3.) Encode Text Variables\n",
    "* Ship name and cruise line are both text variables\n",
    "* We must convert these into numeric variables using categorical encoding\n",
    "* Here, we will use **StringIndexer()**\n",
    "\n",
    "### StringIndexer()\n",
    "* Converts string labels into indexed values\n",
    "* 4 options:\n",
    "    * Descending by frequency (default)\n",
    "    * Ascending by frequency\n",
    "    * Descending alphabetically\n",
    "    * Ascending alphabetically\n",
    "* If two labels occur with the same frequency, alphabetical sorting is used to distinguish them\n",
    "* Indexes calculated are 0 indexed\n",
    "* If a model is trained with x labels and new data includes > x labels, you can choose to:\n",
    "    * Drop any new labels\n",
    "    * Keep new labels and assign to new index (all new labels put into same index)\n",
    "    * Throw an exception (default)\n",
    "* [StringIndexer() Spark Docs](https://spark.apache.org/docs/latest/ml-features#stringindexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hourly-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+---------------+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|Cruise_line_idx|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+---------------+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|           16.0|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|           16.0|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|            1.0|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load string indexer lib\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# create indexer instance\n",
    "indexer = StringIndexer(inputCol='Cruise_line', outputCol='Cruise_line_idx')\n",
    "\n",
    "# fit indexer to data and create index column\n",
    "df_idx = indexer.fit(df).transform(df)\n",
    "\n",
    "# check output\n",
    "df_idx.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-balloon",
   "metadata": {},
   "source": [
    "## 4.) Vectorize Features\n",
    "* We must convert our features into a Spark-friendly format\n",
    "* Here, we simply use a VectorAssembler to convert multiple feature columns into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "certain-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|crew|            features|\n",
      "+----+--------------------+\n",
      "|3.55|[6.0,30.276999999...|\n",
      "|3.55|[6.0,30.276999999...|\n",
      "| 6.7|[26.0,47.262,14.8...|\n",
      "+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load vector libs\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# store instructions for feature transformation\n",
    "assembler = VectorAssembler(inputCols=['Age', 'Tonnage', 'passengers', \n",
    "                                       'length', 'cabins', 'passenger_density',\n",
    "                                       'Cruise_line_idx'],\n",
    "                            outputCol='features')\n",
    "\n",
    "# transform features into single features column\n",
    "df_vect = assembler.transform(df_idx)\n",
    "\n",
    "# extract features and lables only\n",
    "df_final = df_vect.select('crew', 'features')\n",
    "\n",
    "# check output\n",
    "df_final.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-chair",
   "metadata": {},
   "source": [
    "## 5.) Build Regression Model\n",
    "* Split data 70:30 train:test\n",
    "* Fit model to train data\n",
    "* Evaluate test data (act vs pred)\n",
    "* Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "characteristic-fraction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  0.3948335210756415|\n",
      "| -0.8393980014055366|\n",
      "| -0.0954473737173771|\n",
      "|0.005568388964199755|\n",
      "| -1.1989041805894969|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load linear regression libs\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# split data into train/test 70/30\n",
    "train, test = df_final.randomSplit([0.7, 0.3])\n",
    "\n",
    "# create linear regression model instance\n",
    "lr = LinearRegression(featuresCol='features',\n",
    "                      labelCol='crew',\n",
    "                      predictionCol='predictions')\n",
    "\n",
    "# fit model to train data\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "# evaluate test results\n",
    "# i.e. act vs. pred\n",
    "test_results = lr_model.evaluate(test)\n",
    "\n",
    "# check residuals (i.e. variance between act and pred)\n",
    "test_results.residuals.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-adrian",
   "metadata": {},
   "source": [
    "## 6.) Evaluate Model\n",
    "* Our r2 value is quite high at ~97%\n",
    "* Our RMSE is 0.69 which is pretty low compared to our mean (7.8) and std (3.5) for example\n",
    "* Overall this looks like a good fit for our data\n",
    "* The above residuals also look pretty small, suggesting little variance to our model\n",
    "* We will also output our predicted crew sizes for our test data and take a look to see if these seem sensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "relative-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.9671694464669325\n",
      "RMSE:  0.6867053882992723\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrics\n",
    "print(\"r2: \", test_results.r2)\n",
    "print(\"RMSE: \", test_results.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "infectious-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|              158|\n",
      "|   mean|7.794177215189873|\n",
      "| stddev|3.503486564627034|\n",
      "|    min|             0.59|\n",
      "|    max|             21.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare to actual data\n",
    "df_final.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-australia",
   "metadata": {},
   "source": [
    "## 7.) Predictions\n",
    "* Below we make predictions of crew size based off our test features\n",
    "* You can see that our predictions aren't exactly the same, but they do scale fairly well in comparison with our actual crew sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eastern-pavilion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|            features|        predictions|\n",
      "+--------------------+-------------------+\n",
      "|[22.0,3.341,0.66,...|0.19516647892435846|\n",
      "|[27.0,5.35,1.67,4...| 1.7193980014055366|\n",
      "|[27.0,10.0,2.08,4...| 1.6954473737173772|\n",
      "|[19.0,16.8,2.96,5...| 2.0944316110358003|\n",
      "|[48.0,22.08,8.26,...|  4.698904180589497|\n",
      "+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create unlabelled test data\n",
    "unlabelled_data = test.select('features')\n",
    "\n",
    "# make predictions\n",
    "predictions = lr_model.transform(unlabelled_data)\n",
    "\n",
    "# peek at data\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "static-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|crew|            features|\n",
      "+----+--------------------+\n",
      "|0.59|[22.0,3.341,0.66,...|\n",
      "|0.88|[27.0,5.35,1.67,4...|\n",
      "| 1.6|[27.0,10.0,2.08,4...|\n",
      "| 2.1|[19.0,16.8,2.96,5...|\n",
      "| 3.5|[48.0,22.08,8.26,...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare to actual results\n",
    "test.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
